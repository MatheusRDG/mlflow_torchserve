{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: emotion/split\n",
      "Found cached dataset emotion (C:/Users/Matheus/.cache/huggingface/datasets/dair-ai___emotion/split/1.0.0/cca5efe2dfeb58c1d098e0f9eeb200e9927d889b5a03c67097275dfb5fe463bd)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "230d057fc155443189bce17a3e789d5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"dair-ai/emotion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = dataset['train'].to_pandas().head(16)\n",
    "test_ds = dataset['test'].to_pandas().head(16)\n",
    "val_ds = dataset['validation'].to_pandas().head(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sagui-nlp/debertinha-ptbr-xsmall\")\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\"sagui-nlp/debertinha-ptbr-xsmall\", num_labels=train_ds['label'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[50269, 11, 64, 73, 50266]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('olÃ¡')['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a class to encode the text\n",
    "\n",
    "import torch\n",
    "\n",
    "class TextDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = tokenizer.batch_encode_plus(data['text'].tolist(), truncation=True, padding='max_length', max_length=512, return_tensors='pt')\n",
    "        self.data['labels'] = data['label']\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data['input_ids'])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {key: val[idx] for key, val in self.data.items()}\n",
    "\n",
    "train_dataset = TextDataset(train_ds)\n",
    "val_dataset = TextDataset(val_ds)\n",
    "test_dataset = TextDataset(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLFlow Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow import MlflowClient\n",
    "\n",
    "# start the mlflow server\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:8080\")\n",
    "\n",
    "# mlflow server --host 127.0.0.1 --port 8080\n",
    "client = MlflowClient(tracking_uri=\"http://127.0.0.1:8080\")\n",
    "\n",
    "# create a new experiment\n",
    "\n",
    "experiment_tags = {\n",
    "    \"project_name\": \"emotion-classification-debertinha\",\n",
    "    \"team\": \"nlp\",\n",
    "    \"mlflow.note.content\": \"emotion classification with debertinha\",\n",
    "}\n",
    "\n",
    "experiment_id = client.create_experiment(name=\"emotion-classification\", tags=experiment_tags)\n",
    "\n",
    "experiment = mlflow.set_experiment(\"emotion-classification\")\n",
    "\n",
    "run_name = \"emotion-classification-debertinha-run\"\n",
    "\n",
    "artifact_path = \"emotion-classification-debertinha\"\n",
    "\n",
    "# create a new run\n",
    "# run = client.create_run(experiment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 - Loss: 1.7073\n",
      "Epoch 2/5 - Loss: 1.6896\n",
      "Epoch 3/5 - Loss: 1.6700\n",
      "Epoch 4/5 - Loss: 1.6454\n",
      "Epoch 5/5 - Loss: 1.6252\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "lr = 2e-5\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "criteria = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "model = model.to(device)\n",
    "\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        loss = criteria(outputs.logits, labels)\n",
    "        epoch_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss.append(epoch_loss / len(train_loader))\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        eval_loss = 0\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            loss = criteria(outputs.logits, labels)\n",
    "            eval_loss += loss.item()\n",
    "\n",
    "        val_loss.append(eval_loss / len(val_loader))\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/02/24 21:10:29 WARNING mlflow.utils.requirements_utils: Found torch version (2.0.1+cu117) contains a local version label (+cu117). MLflow logged a pip requirement for this package as 'torch==2.0.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2024/02/24 21:10:33 WARNING mlflow.utils.requirements_utils: Found torch version (2.0.1+cu117) contains a local version label (+cu117). MLflow logged a pip requirement for this package as 'torch==2.0.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "c:\\Users\\Matheus\\miniconda3\\envs\\dl_venv\\lib\\site-packages\\_distutils_hack\\__init__.py:18: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Matheus\\miniconda3\\envs\\dl_venv\\lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "with mlflow.start_run(run_name=run_name, experiment_id=experiment_id) as run:\n",
    "    mlflow.log_params({\n",
    "        \"epochs\": epochs,\n",
    "        \"lr\": lr,\n",
    "        \"batch_size\": 8,\n",
    "        \"device\": device.type\n",
    "    })\n",
    "\n",
    "    for index, loss in enumerate(train_loss):\n",
    "        mlflow.log_metric(\"train_loss\", loss, step=index)\n",
    "        mlflow.log_metric(\"val_loss\", val_loss[index], step=index)\n",
    "\n",
    "    train_ds.to_csv(\"data/train.csv\", index=False)\n",
    "    val_ds.to_csv(\"data/val.csv\", index=False)\n",
    "    test_ds.to_csv(\"data/test.csv\", index=False)\n",
    "\n",
    "    mlflow.log_artifact(\"data/train.csv\", artifact_path + \"/data\")\n",
    "    mlflow.log_artifact(\"data/val.csv\", artifact_path + \"/data\")\n",
    "    mlflow.log_artifact(\"data/test.csv\", artifact_path + \"/data\")\n",
    "\n",
    "    #save tokenizer\n",
    "    tokenizer.save_pretrained(artifact_path + \"/tokenizer\")\n",
    "\n",
    "    for file in os.listdir(artifact_path + \"/tokenizer\"):\n",
    "        mlflow.log_artifact(artifact_path + \"/tokenizer/\" + file, artifact_path + \"/tokenizer\")\n",
    "\n",
    "    # delete the tokenizer folder\n",
    "    os.system(f\"rm -rf {artifact_path}/tokenizer\")\n",
    "\n",
    "    #mlflow.pytorch.save_model(model, artifact_path)\n",
    "    \n",
    "    mlflow.pytorch.log_model(model, artifact_path + \"/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'emotion-classification-debertinha'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artifact_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict with model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/02/24 22:09:55 WARNING mlflow.utils.requirements_utils: Found torch version (2.0.1+cu117) contains a local version label (+cu117). MLflow logged a pip requirement for this package as 'torch==2.0.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2024/02/24 22:09:55 WARNING mlflow.utils.requirements_utils: Found torchvision version (0.15.2+cu118) contains a local version label (+cu118). MLflow logged a pip requirement for this package as 'torchvision==0.15.2' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2024/02/24 22:10:01 WARNING mlflow.utils.requirements_utils: Found torch version (2.0.1+cu117) contains a local version label (+cu117). MLflow logged a pip requirement for this package as 'torch==2.0.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"
     ]
    }
   ],
   "source": [
    "transformer_model = {\"model\": model, \"tokenizer\": tokenizer}\n",
    "task = \"text-classification\"\n",
    "\n",
    "with mlflow.start_run(run_name=run_name, experiment_id=experiment_id) as run:\n",
    "    model_info = mlflow.transformers.log_model(\n",
    "        transformers_model=transformer_model,\n",
    "        artifact_path=\"text_classifier\",\n",
    "        task=task,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d1bd5a7b5fd4c73a01bdf93a1000121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/02/24 22:10:57 INFO mlflow.store.artifact.artifact_repo: The progress bar can be disabled by setting the environment variable MLFLOW_ENABLE_ARTIFACTS_PROGRESS_BAR to false\n",
      "2024/02/24 22:11:28 WARNING mlflow.transformers: Could not specify device parameter for this pipeline type\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LABEL_2</td>\n",
       "      <td>0.196948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LABEL_0</td>\n",
       "      <td>0.199091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LABEL_2</td>\n",
       "      <td>0.193724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label     score\n",
       "0  LABEL_2  0.196948\n",
       "1  LABEL_0  0.199091\n",
       "2  LABEL_2  0.193724"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logged_model = 'runs:/bf5f21c3e1764f8d86fe6f6126633d70/text_classifier'\n",
    "\n",
    "# Load model as a PyFuncModel.\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model)\n",
    "\n",
    "# Predict on a Pandas DataFrame.\n",
    "import pandas as pd\n",
    "loaded_model.predict(pd.DataFrame({\"text\": [\"Eu estou muito feliz\", \"Estou triste\", \"Estou com raiva\"]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec3673f6b3094faf8c171f283be4979b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/02/24 22:13:10 INFO mlflow.store.artifact.artifact_repo: The progress bar can be disabled by setting the environment variable MLFLOW_ENABLE_ARTIFACTS_PROGRESS_BAR to false\n",
      "2024/02/24 22:13:44 INFO mlflow.transformers: 'runs:/bf5f21c3e1764f8d86fe6f6126633d70/text_classifier' resolved as 'mlflow-artifacts:/423481557471868563/bf5f21c3e1764f8d86fe6f6126633d70/artifacts/text_classifier'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e939eea0b07f4ca38206709149b88542",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/02/24 22:13:44 WARNING mlflow.transformers: Could not specify device parameter for this pipeline type\n"
     ]
    }
   ],
   "source": [
    "loaded_pipeline = mlflow.transformers.load_model(\n",
    "    model_info.model_uri, return_type=\"pipeline\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_kwargs = {'padding':True,'truncation':True,'max_length':512,'return_tensors':'pt'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.pipelines.text_classification.TextClassificationPipeline"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(loaded_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_0', 'score': 0.19527024030685425},\n",
       " {'label': 'LABEL_0', 'score': 0.1908813863992691}]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kwargs = {\"truncation\": True, \"padding\": \"max_length\", \"max_length\": 1}\n",
    "result = loaded_pipeline(['olÃ¡', 'ok'], **kwargs)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1953, 0.1893, 0.1502, 0.1853, 0.1468, 0.1331],\n",
       "        [0.1909, 0.1878, 0.1550, 0.1841, 0.1489, 0.1333]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare directly inference\n",
    "\n",
    "_data = tokenizer.batch_encode_plus(['olÃ¡', 'ok'], truncation=True, padding='max_length', max_length=512, return_tensors='pt')\n",
    "outputs = model(**_data)\n",
    "\n",
    "#print probability of each class\n",
    "outputs.logits.softmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_venv_39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
